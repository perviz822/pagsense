{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4cc7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,recall_score,precision_score,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac56fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df = pd.read_csv('unlabeled_pool.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4cbcaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove multiword phrases  e.g (\"good afternoon\" )\n",
    "unlabeled_df = unlabeled_df[~unlabeled_df['headword'].str.contains(r'\\s')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8e1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first form from slash-separated words (e.g., \"color/colour\" → \"color\")\n",
    "unlabeled_df['headword'] = unlabeled_df['headword'].str.split('/').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa936b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df = unlabeled_df.drop_duplicates(subset='headword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e5bb65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "def max_depth(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    return max([len(hyp_path) for s in synsets for hyp_path in s.hypernym_paths()] or [0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a57d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df['wordnet_depth'] = unlabeled_df['headword'].apply(max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b21357a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Map CEFR to numeric complexity\n",
    "cefr_map = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "unlabeled_pool = unlabeled_df.copy()\n",
    "unlabeled_pool = unlabeled_pool[unlabeled_pool['CEFR'].isin(cefr_map)]  # drop NaNs or unknowns\n",
    "unlabeled_pool['cefr_score'] = unlabeled_pool['CEFR'].map(cefr_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1437106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done! You labeled 30 words.\n",
      "{'facial': 0, 'solicit': 1, 'perceive': 0, 'proprietary': 1, 'naughty': 0, 'imperceptible': 1, 'glorious': 0, 'connotation': 1, 'temptation': 0, 'archetype': 1, 'exclusion': 0, 'exaltedly': 1, 'inevitable': 0, 'venomous': 0, 'exalted': 1, 'hitherto': 1, 'page': 0, 'catastrophically': 0, 'indolence': 1, 'anthology': 1, 'cancer': 0, 'philanthropy': 0, 'chronologically': 0, 'drabness': 1, 'melancholy': 0, 'precocious': 1, 'innuendo': 1, 'conduit': 1, 'ginger': 0, 'imperceptibly': 1, 'chase': 0, 'philistine': 1, 'burglary': 0, 'philanthropist': 0, 'chronology': 0, 'contraption': 1, 'induce': 1, 'painstaking': 1, 'strawberry': 0, 'melodious': 0, 'brink': 1, 'angst': 1, 'advantage': 0, 'deviantly': 1, 'muscle-bound': 1, 'trophy': 0, 'supporter': 0, 'lyrical': 0, 'enabler': 1, 'fluctuation': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dictionary to store user labels\n",
    "train_word_labels = {}\n",
    "\n",
    "# Loop: exactly 30 user-labeled words\n",
    "while len(train_word_labels) < 50 and not unlabeled_pool.empty:\n",
    "    num_labeled = len(train_word_labels)\n",
    "    num_simple = sum(1 for lbl in train_word_labels.values() if lbl == 0)\n",
    "    simple_ratio = num_simple / (num_labeled + 1e-6)\n",
    "\n",
    "    # Adjust sampling strategy based on how many \"0\" (simple) were labeled\n",
    "    if simple_ratio < 0.5:\n",
    "        # Balanced or complex leaning — random sample\n",
    "        sample_pool = unlabeled_pool.sample(n=10, random_state=random.randint(0, 10000))\n",
    "    else:\n",
    "        # User thinks many words are simple — bias toward complex\n",
    "        top_half = unlabeled_pool.sort_values(by='cefr_score', ascending=False)\n",
    "        sample_pool = top_half.head(30).sample(n=10, random_state=random.randint(0, 10000))\n",
    "\n",
    "    # Choose one word from the sample\n",
    "    row = sample_pool.sample(1, random_state=random.randint(0, 10000)).iloc[0]\n",
    "    word = row['headword']\n",
    "\n",
    "    # Ask user to annotate\n",
    "    while True:\n",
    "        label = input(f\"Label word {num_labeled+1}/30 — Enter 0 (simple) or 1 (complex) for '{word}': \")\n",
    "        if label in ['0', '1']:\n",
    "            train_word_labels[word] = int(label)\n",
    "            # Remove word from pool\n",
    "            unlabeled_pool = unlabeled_pool[unlabeled_pool['headword'] != word]\n",
    "            break\n",
    "        else:\n",
    "            print(\"❌ Invalid input. Please enter 0 or 1.\")\n",
    "\n",
    "print(\"\\n✅ Done! You labeled 30 words.\")\n",
    "print(train_word_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cce8805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            headword  wordnet_depth  freq  is_complex  len\n",
      "0          advantage              7  4.78           0    9\n",
      "1           burglary             11  3.44           0    8\n",
      "2             cancer             13  4.93           0    6\n",
      "3              chase             13  4.44           0    5\n",
      "4          exclusion             10  3.68           0    9\n",
      "5             ginger             10  3.93           0    6\n",
      "6           glorious              1  4.08           0    8\n",
      "7         inevitable              7  4.08           0   10\n",
      "8            naughty              1  3.83           0    7\n",
      "9               page             12  5.12           0    4\n",
      "10          perceive              2  3.72           0    8\n",
      "11        strawberry             12  3.72           0   10\n",
      "12         supporter             10  4.07           0    9\n",
      "13        temptation              8  3.72           0   10\n",
      "14            trophy              7  4.17           0    6\n",
      "15            facial             12  4.10           0    6\n",
      "16      muscle-bound              1  4.15           1   12\n",
      "17       painstaking              1  2.93           1   11\n",
      "18       contraption              8  2.82           1   11\n",
      "19           enabler              0  2.74           1    7\n",
      "20       fluctuation              8  2.89           0   11\n",
      "21           lyrical              1  3.43           0    7\n",
      "22           solicit              7  3.06           1    7\n",
      "23      philanthropy              9  3.32           0   12\n",
      "24    philanthropist             11  3.12           0   14\n",
      "25        precocious              1  2.86           1   10\n",
      "26       connotation              8  2.94           1   11\n",
      "27        philistine             10  2.58           1   10\n",
      "28          innuendo             10  2.90           1    8\n",
      "29            induce              4  3.56           1    6\n",
      "30         anthology             11  3.48           1    9\n",
      "31           conduit              8  3.28           1    7\n",
      "32        chronology              9  3.22           0   10\n",
      "33   chronologically              1  2.91           0   15\n",
      "34       proprietary              5  3.67           1   11\n",
      "35     imperceptible              1  2.49           1   13\n",
      "36     imperceptibly              1  2.24           1   13\n",
      "37  catastrophically              1  2.42           0   16\n",
      "38         indolence              6  2.08           1    9\n",
      "39         deviantly              0  0.00           1    9\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "unlabeled_features = unlabeled_df.copy()\n",
    "if 'is_complex' in unlabeled_features.columns:\n",
    "    unlabeled_features = unlabeled_features.drop(columns=['is_complex'])\n",
    "\n",
    "# Step 3 — filter for the labeled words\n",
    "labeled_words_df = unlabeled_features[\n",
    "    unlabeled_features['headword'].isin(train_word_labels.keys())\n",
    "].copy()\n",
    "\n",
    "# Step 4 — map the labels into a new column\n",
    "labeled_words_df['is_complex'] = labeled_words_df['headword'].map(train_word_labels)\n",
    "\n",
    "# This is now your training set\n",
    "train_df = labeled_words_df.reset_index(drop=True)\n",
    "\n",
    "# Optional: Show the result\n",
    "print(train_df[['headword', 'wordnet_depth', 'freq', 'is_complex','len']].head(40))\n",
    "\n",
    "print(len(train_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8df69",
   "metadata": {},
   "source": [
    "<h1> Load the test and train words for the user <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7e558db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Done! You labeled 30 words.\n",
      "{'disparaging': 1, 'lavatory': 1, 'craft': 0, 'conquer': 0, 'announcement': 0, 'wordsmith': 1, 'some': 0, 'moribund': 1, 'recipe': 0, 'remittance': 1, 'merchandise': 1, 'simplicity': 0, 'receptionist': 0, 'intrinsic': 0, 'materialize': 0, 'promotable': 1, 'munificence': 1, 'meteorological': 1, 'factor': 0, 'dissemination': 1, 'father': 0, 'meteorology': 1, 'corporation': 0, 'splinter': 0, 'reproach': 1, 'deviant': 1, 'operator': 0, 'choreography': 1, 'purposeful': 0, 'cosmic': 0}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Map CEFR to numeric complexity\n",
    "cefr_map = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "\n",
    "# Dictionary to store user labels\n",
    "test_word_labels = {}\n",
    "\n",
    "# Loop: exactly 30 user-labeled words\n",
    "while len(test_word_labels) < 30 and not unlabeled_pool.empty:\n",
    "    num_labeled = len(test_word_labels)\n",
    "    num_simple = sum(1 for lbl in test_word_labels.values() if lbl == 0)\n",
    "    simple_ratio = num_simple / (num_labeled + 1e-6)\n",
    "\n",
    "    # Adjust sampling strategy based on how many \"0\" (simple) were labeled\n",
    "    if simple_ratio < 0.5:\n",
    "        # Balanced or complex leaning — random sample\n",
    "        sample_pool = unlabeled_pool.sample(n=10, random_state=random.randint(0, 10000))\n",
    "    else:\n",
    "        # User thinks many words are simple — bias toward complex\n",
    "        top_half = unlabeled_pool.sort_values(by='cefr_score', ascending=False)\n",
    "        sample_pool = top_half.head(30).sample(n=10, random_state=random.randint(0, 10000))\n",
    "\n",
    "    # Choose one word from the sample\n",
    "    row = sample_pool.sample(1, random_state=random.randint(0, 10000)).iloc[0]\n",
    "    word = row['headword']\n",
    "\n",
    "    # Ask user to annotate\n",
    "    while True:\n",
    "        label = input(f\"Label word {num_labeled+1}/30 — Enter 0 (simple) or 1 (complex) for '{word}': \")\n",
    "        if label in ['0', '1']:\n",
    "            test_word_labels[word] = int(label)\n",
    "            # Remove word from pool\n",
    "            unlabeled_pool = unlabeled_pool[unlabeled_pool['headword'] != word]\n",
    "            break\n",
    "        else:\n",
    "            print(\"❌ Invalid input. Please enter 0 or 1.\")\n",
    "\n",
    "print(\"\\n✅ Done! You labeled 30 words.\")\n",
    "print(test_word_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d3a1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop_duplicates(subset='headword', keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbccee47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [headword, wordnet_depth, freq, is_complex, len]\n",
      "Index: []\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "unlabeled_features = unlabeled_pool.copy()\n",
    "if 'is_complex' in unlabeled_features.columns:\n",
    "    unlabeled_features = unlabeled_features.drop(columns=['is_complex'])\n",
    "\n",
    "# Step 3 — filter for the labeled words\n",
    "labeled_words_df = unlabeled_features[\n",
    "    unlabeled_features['headword'].isin(test_word_labels.keys())\n",
    "].copy()\n",
    "\n",
    "# Step 4 — map the labels into a new column\n",
    "labeled_words_df['is_complex'] = labeled_words_df['headword'].map(test_word_labels)\n",
    "\n",
    "# This is now your training set\n",
    "test_df = labeled_words_df.reset_index(drop=True)\n",
    "\n",
    "# Optional: Show the result\n",
    "print(test_df[['headword', 'wordnet_depth', 'freq', 'is_complex','len']].head(40))\n",
    "\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ded1f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop_duplicates(subset='headword', keep='first').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e089775b",
   "metadata": {},
   "source": [
    "<h1> Choose features <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f771167e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features =['freq','len','wordnet_depth']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77d6701",
   "metadata": {},
   "source": [
    "$$\n",
    "H(\\mathbf{p}) = -\\sum_{i=1}^{C} p_i \\log(p_i + \\varepsilon)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8acf8ef",
   "metadata": {},
   "source": [
    "<h1> Active Learning process <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67fb96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_active_learning(n, model, scaler, unlabeled_df, train_df, features):\n",
    "    for _ in range(n):\n",
    "        # Scale unlabeled data\n",
    "        unlabeled_train_scaled = scaler.transform(unlabeled_df[features])\n",
    "        class_ratio = train_df['is_complex'].mean()\n",
    "        \n",
    "\n",
    "        # Make predictions\n",
    "        probas = model.predict_proba(unlabeled_train_scaled)\n",
    "        \n",
    "        # Select sample (most uncertain)\n",
    "        uncertainties = -np.sum(probas * np.log(probas + 1e-10), axis=1)\n",
    "\n",
    "        if class_ratio < 0.5:\n",
    "            selected_idx =  np.argmax(probas[:, 1]) \n",
    "        else:    \n",
    "         selected_idx = np.argsort(uncertainties)[-1]\n",
    "         \n",
    "        selected_index = unlabeled_df.index[selected_idx]\n",
    "        selected_sample = unlabeled_df.loc[[selected_index]].copy()\n",
    "        \n",
    "        # Annotation\n",
    "        while True:\n",
    "            try:\n",
    "                word = selected_sample['headword'].iloc[0]\n",
    "                label = int(input(f\"Enter 0 if simple, 1 if complex for '{word}': \"))\n",
    "                if label in [0, 1]:\n",
    "                    break\n",
    "                print(\"Please enter 0 or 1.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Enter 0 or 1.\")\n",
    "        \n",
    "        # Update data\n",
    "        selected_sample['is_complex'] = label\n",
    "        unlabeled_df.drop(index=selected_index, inplace=True)\n",
    "        train_df = pd.concat([train_df, selected_sample], ignore_index=True)\n",
    "        \n",
    "        # Retrain model\n",
    "        X_train_scaled = scaler.transform(train_df[features])\n",
    "        model = LogisticRegression().fit(X_train_scaled, train_df['is_complex'])\n",
    "    \n",
    "    return model, scaler, unlabeled_df, train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "950df5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(train_df[features])\n",
    "model = LogisticRegression().fit(X_train_scaled, train_df['is_complex'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model, scaler, unlabeled_df, train_df = initiate_active_learning(\n",
    "    n=30,\n",
    "    model=model,\n",
    "    scaler=scaler,\n",
    "    unlabeled_df=unlabeled_pool,\n",
    "    train_df=train_df,\n",
    "    features=features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52ad4c",
   "metadata": {},
   "source": [
    "<h1> Analyse the performance metrics <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72a2ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3175111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_predictor(test_df, freq_threshold=4):\n",
    "    \"\"\"\n",
    "    Predicts word complexity based on frequency:\n",
    "    - If frequency > threshold → Simple (0)\n",
    "    - Else → Complex (1)\n",
    "    \n",
    "    Args:\n",
    "        test_df (pd.DataFrame): DataFrame containing 'freq' column.\n",
    "        freq_threshold (int): Frequency cutoff (default=4).\n",
    "    \n",
    "    Returns:\n",
    "        y_pred (list): Predicted labels (0 for simple, 1 for complex).\n",
    "    \"\"\"\n",
    "    y_pred = (test_df['freq'] <= freq_threshold).astype(int).tolist()\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d341e599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    freq  len  wordnet_depth\n",
      "0   4.78    9              7\n",
      "1   3.44    8             11\n",
      "2   4.93    6             13\n",
      "3   4.44    5             13\n",
      "4   3.68    9             10\n",
      "..   ...  ...            ...\n",
      "75  3.08    9              1\n",
      "76  3.30    7              4\n",
      "77  0.00    9              1\n",
      "78  3.42    6              8\n",
      "79  3.85    3              9\n",
      "\n",
      "[80 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30980737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [freq, len, wordnet_depth]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(test_df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82755c0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m y_f = frequency_predictor(test_df, freq_threshold=test_df[\u001b[33m'\u001b[39m\u001b[33mis_complex\u001b[39m\u001b[33m'\u001b[39m].mean())\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y_pred = model.predict(\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      3\u001b[39m y_true = test_df[\u001b[33m'\u001b[39m\u001b[33mis_complex\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m personalized_accuracy = accuracy_score(y_true, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/pagesense/venv/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/pagesense/venv/lib/python3.13/site-packages/sklearn/preprocessing/_data.py:1075\u001b[39m, in \u001b[36mStandardScaler.transform\u001b[39m\u001b[34m(self, X, copy)\u001b[39m\n\u001b[32m   1072\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1074\u001b[39m copy = copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy\n\u001b[32m-> \u001b[39m\u001b[32m1075\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparse.issparse(X):\n\u001b[32m   1087\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.with_mean:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/pagesense/venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/pagesense/venv/lib/python3.13/site-packages/sklearn/utils/validation.py:1128\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1126\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1129\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1130\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1131\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1132\u001b[39m         )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1135\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 3)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "y_f = frequency_predictor(test_df, freq_threshold=test_df['is_complex'].mean())\n",
    "y_pred = model.predict(scaler.transform(test_df[features]))\n",
    "y_true = test_df['is_complex']\n",
    "\n",
    "personalized_accuracy = accuracy_score(y_true, y_pred)\n",
    "personalized_confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "personalized_f1 = f1_score(y_true, y_pred)\n",
    "personalized_recall = recall_score(y_true, y_pred)\n",
    "personalized_precision = precision_score(y_true, y_pred)\n",
    "personalized_kappa = cohen_kappa_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Model Evaluation Metrics:\")\n",
    "print(f\"{'Accuracy:':<20} {personalized_accuracy:.2f}\")\n",
    "print(f\"{'Confusion Matrix:':<20}\\n{personalized_confusion_matrix}\")\n",
    "print(f\"{'F1 Score:':<20} {personalized_f1:.2f}\")\n",
    "print(f\"{'Recall Score:':<20} {personalized_recall:.2f}\")\n",
    "print(f\"{'Precision Score:':<20} {personalized_precision:.2f}\")\n",
    "print(f\"{'Kohen:':<20} {personalized_kappa:.2f}\")\n",
    "\n",
    "# Calculate frequency-based metrics\n",
    "freq_accuracy = accuracy_score(y_true, y_f)\n",
    "freq_confusion_matrix = confusion_matrix(y_true, y_f)\n",
    "freq_f1 = f1_score(y_true, y_f)\n",
    "freq_recall = recall_score(y_true, y_f)\n",
    "freq_precision = precision_score(y_true, y_f)\n",
    "freq_kappa = cohen_kappa_score(y_true, y_f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the metrics (same as before)\n",
    "print(f\"Model Evaluation Metrics for frequency:\")\n",
    "print(f\"{'Accuracy:':<20} {freq_accuracy:.2f}\")\n",
    "print(f\"{'Confusion Matrix:':<20}\\n{freq_confusion_matrix}\")\n",
    "print(f\"{'F1 Score:':<20} {freq_f1:.2f}\")\n",
    "print(f\"{'Recall Score:':<20} {freq_recall:.2f}\")\n",
    "print(f\"{'Precision Score:':<20} {freq_precision:.2f}\")\n",
    "print(f\"{'Kohens Kappa:':<20} {freq_kappa:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Sample data or replace with your actual data\n",
    "\n",
    "\n",
    "\n",
    "# Define the columns for our metrics DataFrame\n",
    "columns = [\n",
    "    'timestamp', \n",
    "    'accuracy', \n",
    "    'f1_score', \n",
    "    'recall', \n",
    "    'precision', \n",
    "    'kappa', \n",
    "    'confusion_matrix', \n",
    "    'threshold_used'\n",
    "]\n",
    "\n",
    "# Try to load existing DataFrame or create new one\n",
    "try:\n",
    "    df = pd.read_csv('metrics_log.csv')  # Or read from your existing storage\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Create metrics dictionary\n",
    "metrics = {\n",
    "    'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'accuracy': (accuracy_score(y_true, y_pred), accuracy_score(y_true, y_f)),\n",
    "    'f1_score': (f1_score(y_true, y_pred), f1_score(y_true, y_f)),\n",
    "    'recall': (recall_score(y_true, y_pred), recall_score(y_true, y_f)),\n",
    "    'precision': (precision_score(y_true, y_pred), precision_score(y_true, y_f)),\n",
    "    'kappa': (cohen_kappa_score(y_true, y_pred), cohen_kappa_score(y_true, y_f)),\n",
    "    'confusion_matrix': (\n",
    "        str(confusion_matrix(y_true, y_pred)), \n",
    "        str(confusion_matrix(y_true, y_f))\n",
    "    ),\n",
    "    'threshold_used': test_df['is_complex'].mean()\n",
    "}\n",
    "\n",
    "# Append metrics (using modern pandas concat instead of deprecated append)\n",
    "df = pd.concat([df, pd.DataFrame([metrics])], ignore_index=True)\n",
    "\n",
    "# Save to CSV (or your preferred storage)\n",
    "df.to_csv('metrics_log.csv', index=False)\n",
    "\n",
    "print(\"Metrics successfully logged:\")\n",
    "print(df.tail())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aff7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "[0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_f)\n",
    "print(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
